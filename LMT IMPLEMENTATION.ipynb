{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Exclude origin for brevity\n",
    "training_columns = ['cylinders','displacement','horsepower','weight',\n",
    "                    'acceleration','model_year']\n",
    "\n",
    "df=pd.read_csv('heart.csv')\n",
    "dataX=df.iloc[:,:-1]\n",
    "datay=df.iloc[:,-1]\n",
    "seed=8\n",
    "X_train, X_test, y_train, y_test =train_test_split(dataX,datay,test_size=0.2,random_state=seed)\n",
    "\n",
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "training_columns=X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw ridge\n",
      "-0.1735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression()\n",
    "#alpha_values = np.array([0.25,0.5,1,2,4,8,16])\n",
    "#param_grid = dict(alpha=alpha_values)\n",
    "#kfold = KFold(n_splits=10, random_state=seed)\n",
    "#grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv=kfold, scoring='neg_mean_squared_error')\n",
    "#grid_result = grid.fit(X, Y)\n",
    "\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#grid_result = lr.fit(X, Y)\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#lr = Ridge(**grid_result.best_params_)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "scores = cross_val_score(lr, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print('Raw ridge')\n",
    "\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scale inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nscaled_lr = Pipeline([('Scaler', StandardScaler()),('LR', lr)])\\nscores = cross_val_score(scaled_lr, X, Y, cv=kfold, scoring='neg_mean_squared_error')\\nprint('Scaled ridge')\\nprint(scores.mean())\\ncart_mean_error=scores.mean()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scaled_lr = Pipeline([('Scaler', StandardScaler()),('LR', lr)])\n",
    "scores = cross_val_score(scaled_lr, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print('Scaled ridge')\n",
    "print(scores.mean())\n",
    "cart_mean_error=scores.mean()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Evaluation results :\n",
    "The cross-validated mean squared error for linear regression is approximately -0.18583 . This will be the baseline.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef print_coefs(coefs, training_columns):\\n    sorted_idx = np.argsort(-abs(coefs)) # negative for descending\\n    for (name, coef) in zip(np.array(training_columns)[sorted_idx], coefs[sorted_idx]):\\n        print(\"%s: %f\" % (name, coef))\\n\\ndef plot_coefs(coefs, training_columns, title_suffix=\\'\\'):\\n    sorted_idx = np.argsort(abs(coefs))\\n    pos = np.arange(len(coefs)) + .5\\n    plt.subplot(1, 2, 2)\\n    plt.barh(pos, coefs[sorted_idx], align=\\'center\\')\\n    plt.yticks(pos, np.array(training_columns)[sorted_idx])\\n    plt.xlabel(\\'Coef value\\')\\n    plt.title(\\'Coefficents\\' + title_suffix)\\n    plt.xlim(-5.5, 5.5)\\n    plt.show()\\n\\n# use scaled model\\nlr.fit(X, Y)\\nprint_coefs(lr.coef_, training_columns)\\nplot_coefs(lr.coef_, training_columns)\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def print_coefs(coefs, training_columns):\n",
    "    sorted_idx = np.argsort(-abs(coefs)) # negative for descending\n",
    "    for (name, coef) in zip(np.array(training_columns)[sorted_idx], coefs[sorted_idx]):\n",
    "        print(\"%s: %f\" % (name, coef))\n",
    "\n",
    "def plot_coefs(coefs, training_columns, title_suffix=''):\n",
    "    sorted_idx = np.argsort(abs(coefs))\n",
    "    pos = np.arange(len(coefs)) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, coefs[sorted_idx], align='center')\n",
    "    plt.yticks(pos, np.array(training_columns)[sorted_idx])\n",
    "    plt.xlabel('Coef value')\n",
    "    plt.title('Coefficents' + title_suffix)\n",
    "    plt.xlim(-5.5, 5.5)\n",
    "    plt.show()\n",
    "\n",
    "# use scaled model\n",
    "lr.fit(X, Y)\n",
    "print_coefs(lr.coef_, training_columns)\n",
    "plot_coefs(lr.coef_, training_columns)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.156712 using {'max_depth': 6, 'min_samples_leaf': 10}\n",
      "CART\n",
      "-0.15982791434990334\n",
      "Wrote output to ./auto_mpg.graphviz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Grid search meta parameters\n",
    "param_grid = dict(min_samples_leaf=np.array([1,5,10,50,100,200]), max_depth=np.array([2,4,6,8,10]))\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "grid = GridSearchCV(estimator=dt, param_grid=param_grid, cv=kfold, scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Evaluate best model\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "dt = DecisionTreeRegressor(**grid_result.best_params_)\n",
    "scores = cross_val_score(dt, X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print('CART')\n",
    "cart_mean_error=scores.mean()\n",
    "print(scores.mean())\n",
    "\n",
    "# Serialize tree structure for investigation\n",
    "dt.fit(X, Y)\n",
    "output_file = './auto_mpg.graphviz'\n",
    "export_graphviz(dt, out_file=output_file, feature_names = X.columns)\n",
    "print(\"Wrote output to \" + output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation results:\n",
    "The cross-validated mean squared error is for our CART tree is approximately -0.15898986807217172. This is worse than the linear model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gradient Boosting Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT\n",
      "-0.14577162069822247\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "scores = cross_val_score(GradientBoostingRegressor(), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print('GBT')\n",
    "print(scores.mean())\n",
    "\n",
    "clf = GradientBoostingRegressor()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "feature_importance = clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "\n",
    "gb_mean_error=scores.mean()\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('GBT Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Evaluation results and insights\n",
    "The cross-validated mean squared error from GBT is approximately -0.14789370. This is better than the simple decision tree but worse than linear model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logistic model tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape ,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4488448844884489\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import lmtmodel\n",
    "from lmtmodel import LinearModelTree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "\n",
    "shared_scaler = StandardScaler()\n",
    "shared_scaler.fit(X)\n",
    "X = dataX\n",
    "Y = datay\n",
    "def fit_linear_model(x, y):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(shared_scaler.transform(x), y)\n",
    "    return SharedScalerModel(shared_scaler, lr)\n",
    "\n",
    "class SharedScalerModel:\n",
    "    \n",
    "    def __init__(self, scaler, lm):\n",
    "        self.scaler = scaler\n",
    "        self.lm = lm\n",
    "        self.coef_ = lm.coef_\n",
    "        self.intercept_ = lm.intercept_\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.lm.predict(self.scaler.transform(X))\n",
    "\n",
    "\n",
    "MIN_NODE_SIZE =40\n",
    "#best_score={}\n",
    "#best_min_split_improvement=[0.003,0.01,0.05,0.1,0.2,0.5]\n",
    "\n",
    "#for MIN_SPLIT_IMPROVEMENT in best_min_split_improvement :\n",
    "MIN_SPLIT_IMPROVEMENT=0.1\n",
    "lmt = LinearModelTree(MIN_NODE_SIZE, fit_linear_model, min_split_improvement=MIN_SPLIT_IMPROVEMENT)\n",
    "\n",
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "scores = []\n",
    "for train_index, test_index in kfold.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index] \n",
    "    lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "    y_pred = lmt.predict(X_test.values, X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    scores.append(mse)\n",
    "print(np.array(scores).mean())\n",
    "#best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a tree on the full dataset, and serialize it to see the feature splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "152.0\n",
      "not none\n",
      "2\n",
      "2.0\n",
      "not none\n",
      "4\n",
      "237.0\n",
      "not none\n",
      "None\n",
      "None\n",
      "43 [-1.11084901  0.15123862 -0.33402519] [[ 2.34344693e-01 -6.04589865e-01  7.14662464e-01  1.18891729e-01\n",
      "   8.95589851e-01 -1.28828738e-01  7.26007807e-02  8.37357152e-01\n",
      "   4.23506267e-01 -5.74550137e-01 -9.90413671e-02 -4.47858751e-01\n",
      "   5.06030663e-02]\n",
      " [-7.32251489e-04 -2.79656832e-01 -2.22305439e-01  1.43605246e-01\n",
      "  -1.22355391e+00  3.47351020e-02 -2.44669343e-01 -5.58445920e-01\n",
      "  -4.85637748e-01  3.36650242e-01 -3.81617478e-01 -7.91681070e-02\n",
      "   2.95444386e-01]\n",
      " [-2.71325313e-01  7.04030281e-01  3.62429340e-01 -1.88909271e-01\n",
      "   1.35930316e+00 -4.09047132e-02  1.10676911e-01  4.20733956e-01\n",
      "   2.13810085e-01 -1.28300284e-02  6.14454689e-01  2.59920633e-01\n",
      "  -3.47853386e-01]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1f9d80d00ff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlmt_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlmt_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Project 3\\heart diseases\\lmtmodel.ipynb\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;32m~\\Project 3\\heart diseases\\lmtmodel.ipynb\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, prefix)\u001b[0m\n",
      "\u001b[1;32m~\\Project 3\\heart diseases\\lmtmodel.ipynb\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, prefix)\u001b[0m\n",
      "\u001b[1;32m~\\Project 3\\heart diseases\\lmtmodel.ipynb\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, prefix)\u001b[0m\n",
      "\u001b[1;32m~\\Project 3\\heart diseases\\lmtmodel.ipynb\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, prefix)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "\n",
    "lmt_1= LinearModelTree(MIN_NODE_SIZE, fit_linear_model, MIN_SPLIT_IMPROVEMENT)\n",
    "lmt_1.build_tree(X.values,X, Y.values)\n",
    "\n",
    "lmt_1.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thalach\n",
      "cp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model split on 2 features : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root_lm = lmt.root.lm\n",
    "node_1_coef = root_lm.coef_ + lmt.root.left.lm.coef_\n",
    "plot_coefs(node_1_coef, training_columns, ' (horsepower < 78)')\n",
    "\n",
    "right_coef = lmt.root.right.lm.coef_\n",
    "node_2_coef = root_lm.coef_ + right_coef + lmt.root.right.left.lm.coef_\n",
    "plot_coefs(node_2_coef, training_columns, ' (horsepower >= 78 & horsepower < 97)')\n",
    "\n",
    "\n",
    "node_3_coef = root_lm.coef_ + right_coef + lmt.root.right.right.lm.coef_\n",
    "plot_coefs(node_3_coef, training_columns, ' (horsepower >= 97)')\n",
    "\n",
    "\n",
    "print_coefs(node_1_coef, training_columns)\n",
    "print('')\n",
    "print_coefs(node_2_coef, training_columns)\n",
    "print('')\n",
    "print_coefs(node_3_coef, training_columns)\n",
    "\n",
    "\n",
    "\n",
    "displacement: -5.186292\n",
    "model_year: 4.287827\n",
    "weight: -4.287711\n",
    "horsepower: -1.605432\n",
    "cylinders: 0.685287\n",
    "acceleration: 0.608814\n",
    "\n",
    "weight: -5.522914\n",
    "model_year: 2.410542\n",
    "horsepower: -1.416881\n",
    "acceleration: -0.805342\n",
    "cylinders: -0.311572\n",
    "displacement: -0.156405\n",
    "\n",
    "weight: -2.154847\n",
    "model_year: 1.428982\n",
    "horsepower: -1.089580\n",
    "displacement: 1.041145\n",
    "cylinders: -0.867039\n",
    "acceleration: -0.200428\n",
    "In [430]:\n",
    "rows = 1\n",
    "cols = 3\n",
    "coefs = [\n",
    "    node_1_coef,\n",
    "    node_2_coef,\n",
    "    node_3_coef,\n",
    "]\n",
    "titles = ['Low power', 'Medium power', 'High power']\n",
    "f, axs = plt.subplots(rows, cols, sharex='col', figsize=(12, 4))\n",
    "for col in range(cols):\n",
    "    pos = np.arange(len(coefs[col])) + .5\n",
    "    axs[col].barh(pos, coefs[col], align='center')\n",
    "    axs[col].set_yticks(pos)\n",
    "    axs[col].set_yticklabels(np.array(training_columns))\n",
    "    axs[col].set_xlabel('Coef value')\n",
    "    axs[col].set_title(titles[col])\n",
    "    axs[col].set_xlim(-5.5, 5.5)\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "In [434]:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "def gen(n=40):\n",
    "    return np.random.normal(size=n)\n",
    "\n",
    "rows, cols = 3, 5\n",
    "\n",
    "fsize = 15\n",
    "\n",
    "rownames = ['low power', 'medium power', 'high power']\n",
    "subpop_data = [\n",
    "    df.query('horsepower < 78'),\n",
    "    df.query('horsepower >= 78 & horsepower < 97'),\n",
    "    df.query('horsepower >= 97'),\n",
    "]\n",
    "\n",
    "cmap = sns.color_palette(\"Set2\", cols)\n",
    "\n",
    "f, axs = plt.subplots(rows, cols, sharex='col', figsize=(15, 6))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        _ = axs[i,j].hist(subpop_data[i][training_columns[j]], histtype='step', color=cmap[j])\n",
    "        axs[i,j].set_xticks([])\n",
    "        axs[i,j].set_yticks([])\n",
    "        left, right = _[1][0], _[1][-1]\n",
    "        \n",
    "        # black dots\n",
    "        axs[i,j].scatter(left, 0, c='black', s=15)\n",
    "        axs[i,j].scatter(right, 0, c='black', s=15)\n",
    "        \n",
    "        # min,max annotations\n",
    "        axs[i,j].annotate(str(int(left)), \n",
    "                          xy=(left, 0), \n",
    "                          xytext=(-5, -20),\n",
    "                          textcoords='offset points')\n",
    "        \n",
    "        axs[i,j].annotate(str(int(right)), \n",
    "                          xy=(right, 0), \n",
    "                          xytext=(-5, -20),\n",
    "                          textcoords='offset points')\n",
    "        \n",
    "        if i == 0:\n",
    "            axs[i,j].set_xlabel(training_columns[j], labelpad=15, size=fsize)\n",
    "            axs[i,j].xaxis.set_label_position('top')\n",
    "            \n",
    "        if j == 0:\n",
    "            axs[i,j].set_ylabel(rownames[i], size=fsize)\n",
    "\n",
    "f.subplots_adjust(hspace=1.5)\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
